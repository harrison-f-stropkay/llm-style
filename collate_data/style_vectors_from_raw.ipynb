{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e173ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b49b1",
   "metadata": {},
   "source": [
    "## Only Gemini shown in this notebook, but the same functions were used for all responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea9c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gemini.csv\")\n",
    "df.rename(columns={'index': 'row'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98dc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from the 450 million word Corpus of Contemporary American English (COCA), length = 100\n",
    "most_common_english = ['the', 'to', 'and', 'of', 'a', 'in', 'i', 'that', 'you', 'it', 'is',\n",
    "                       'for', 'on', 'was', 'he', 'with', 'this', 'as', \"n't\", 'we', 'be',\n",
    "                       'have', 'are', 'not', 'but', 'at', 'they', 'do', 'what', 'his', 'from', \n",
    "                       'by', 'or', 'she', 'my', 'all', 'an', 'there', 'so', 'her', 'about',\n",
    "                       'me', 'one', 'had', 'if', 'your', 'can', 'who', 'no', 'out', 'has',\n",
    "                       'their', 'were', 'like', 'just', 'would', 'up', 'when', 'more', 'will',\n",
    "                       'know', 'said', 'did', 'been', 'people', 'get', 'him', 'time', 'them',\n",
    "                       'some', 'how', 'now', 'which', 'could', 'think', 'than', 'our', 'into',\n",
    "                       'other', 'right', 'here', 'well', 'new', 'then', 'because', 'go', 'see',\n",
    "                       'back', 'only', 'these', 'over', 'going', 'us', 'also', 'two', 'first',\n",
    "                       'its', 'even', 'good', 'way']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b667be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function word list pulled from James Oâ€™Shea's research on dialogue act classification, length = 277\n",
    "english_function = [\"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \n",
    "                    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \n",
    "                    \"am\", \"among\", \"amongst\", \"amoungst\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \n",
    "                    \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"around\", \"as\", \"at\", \n",
    "                    \"be\", \"became\", \"because\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \n",
    "                    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"both\", \"but\", \"by\", \"can\", \n",
    "                    \"cannot\", \"could\", \"dare\", \"despite\", \"did\", \"do\", \"does\", \"done\", \"down\", \n",
    "                    \"during\", \"each\", \"eg\", \"either\", \"else\", \"elsewhere\", \"enough\", \"etc\", \"even\", \n",
    "                    \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \n",
    "                    \"first\", \"for\", \"former\", \"formerly\", \"from\", \"further\", \"furthermore\", \"had\", \n",
    "                    \"has\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereabouts\", \"hereafter\", \n",
    "                    \"hereby\", \"herein\", \"hereinafter\", \"heretofore\", \"hereunder\", \"hereupon\", \n",
    "                    \"herewith\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"i\", \n",
    "                    \"ie\", \"if\", \"in\", \"indeed\", \"inside\", \"instead\", \"into\", \"is\", \"it\", \"its\", \n",
    "                    \"itself\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"lot\", \"lots\", \"many\", \n",
    "                    \"may\", \"me\", \"meanwhile\", \"might\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \n",
    "                    \"much\", \"must\", \"my\", \"myself\", \"namely\", \"near\", \"need\", \"neither\", \"never\", \n",
    "                    \"nevertheless\", \"next\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \n",
    "                    \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"oftentimes\", \"on\", \"once\", \"one\", \n",
    "                    \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"ought\", \"our\", \"ours\", \n",
    "                    \"ourselves\", \"out\", \"outside\", \"over\", \"per\", \"perhaps\", \"rather\", \"re\", \n",
    "                    \"same\", \"second\", \"several\", \"shall\", \"she\", \"should\", \"since\", \"so\", \"some\", \n",
    "                    \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \n",
    "                    \"still\", \"such\", \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \n",
    "                    \"then\", \"thence\", \"there\", \"thereabouts\", \"thereafter\", \"thereby\", \"therefore\", \n",
    "                    \"therein\", \"thereof\", \"thereon\", \"thereupon\", \"these\", \"they\", \"third\", \"this\", \n",
    "                    \"those\", \"though\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \n",
    "                    \"too\", \"top\", \"toward\", \"towards\", \"under\", \"until\", \"up\", \"upon\", \"us\", \n",
    "                    \"used\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \n",
    "                    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \n",
    "                    \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \n",
    "                    \"whole\", \"whom\", \"whose\", \"why\", \"whyever\", \"will\", \"with\", \"within\", \"without\", \n",
    "                    \"would\", \"yes\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f30344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, allowed_words):\n",
    "    # Remove punctuation and newline characters, convert to lowercase\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    text = text.translate(translator).replace('\\n', ' ').lower()\n",
    "    \n",
    "    # Keep only words that are in the allowed list\n",
    "    processed_text = ' '.join(word for word in text.split() if word in allowed_words)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8af770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed_common\"] = df[\"response\"].apply(lambda x: process_text(x, most_common_english))\n",
    "df[\"processed_function\"] = df[\"response\"].apply(lambda x: process_text(x, english_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83265341",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb6a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vectorizer.fit_transform(df['processed_function'])\n",
    "\n",
    "dtm_df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "function_df = pd.concat([df, dtm_df], axis=1)\n",
    "\n",
    "\n",
    "exclude_columns = function_df.columns[:6]\n",
    "function_df = pd.DataFrame({\n",
    "    'prompt': function_df.prompt,\n",
    "    'response': function_df.response,\n",
    "    'SummaryVector': function_df.apply(lambda row: row[~row.index.isin(exclude_columns)].values.tolist(), axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2182a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vectorizer.fit_transform(df['processed_common'])\n",
    "\n",
    "dtm_df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "common_df = pd.concat([df, dtm_df], axis=1)\n",
    "\n",
    "exclude_columns = common_df.columns[:6]\n",
    "common_df = pd.DataFrame({\n",
    "    'prompt': common_df.prompt,\n",
    "    'response': common_df.response,\n",
    "    'SummaryVector': common_df.apply(lambda row: row[~row.index.isin(exclude_columns)].values.tolist(), axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5720860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>common_vectors</th>\n",
       "      <th>function_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respond to the following creative writing prom...</td>\n",
       "      <td>In the shadowy realm where space and time inte...</td>\n",
       "      <td>[0, 2, 13, 1, 6, 1, 1, 2, 0, 1, 0, 0, 1, 3, 0,...</td>\n",
       "      <td>[1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Respond to the following creative writing prom...</td>\n",
       "      <td>In the clandestine world of time travel, where...</td>\n",
       "      <td>[0, 2, 17, 0, 10, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Respond to the following creative writing prom...</td>\n",
       "      <td>In the year 2342, time travel had become a pop...</td>\n",
       "      <td>[0, 2, 17, 0, 8, 0, 0, 0, 0, 1, 1, 3, 0, 0, 0,...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Respond to the following creative writing prom...</td>\n",
       "      <td>In the intricate labyrinth of time, where mome...</td>\n",
       "      <td>[0, 6, 11, 0, 7, 0, 0, 0, 0, 0, 2, 3, 0, 2, 0,...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Respond to the following creative writing prom...</td>\n",
       "      <td>In the realm of temporal anomalies and audacio...</td>\n",
       "      <td>[0, 0, 24, 0, 7, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0,...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>To get in Heaven, you have to confront the per...</td>\n",
       "      <td>In the hushed tranquility of the celestial rea...</td>\n",
       "      <td>[1, 2, 14, 0, 1, 0, 0, 1, 0, 3, 4, 0, 0, 0, 0,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>To get in Heaven, you have to confront the per...</td>\n",
       "      <td>As I arrived at the pearly gates of Heaven, my...</td>\n",
       "      <td>[0, 2, 13, 0, 7, 2, 2, 1, 0, 2, 2, 0, 0, 0, 0,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>To get in Heaven, you have to confront the per...</td>\n",
       "      <td>In the ethereal realm, where clouds caressed t...</td>\n",
       "      <td>[0, 3, 8, 0, 6, 0, 1, 1, 0, 1, 4, 3, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>To get in Heaven, you have to confront the per...</td>\n",
       "      <td>In the ethereal realm of the afterlife, I stoo...</td>\n",
       "      <td>[2, 2, 25, 0, 6, 1, 2, 4, 0, 5, 6, 0, 0, 0, 0,...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>To get in Heaven, you have to confront the per...</td>\n",
       "      <td>In the vast expanse of the afterlife, I found ...</td>\n",
       "      <td>[0, 1, 14, 0, 4, 2, 3, 4, 0, 5, 2, 0, 0, 1, 0,...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    Respond to the following creative writing prom...   \n",
       "1    Respond to the following creative writing prom...   \n",
       "2    Respond to the following creative writing prom...   \n",
       "3    Respond to the following creative writing prom...   \n",
       "4    Respond to the following creative writing prom...   \n",
       "..                                                 ...   \n",
       "795  To get in Heaven, you have to confront the per...   \n",
       "796  To get in Heaven, you have to confront the per...   \n",
       "797  To get in Heaven, you have to confront the per...   \n",
       "798  To get in Heaven, you have to confront the per...   \n",
       "799  To get in Heaven, you have to confront the per...   \n",
       "\n",
       "                                              response  \\\n",
       "0    In the shadowy realm where space and time inte...   \n",
       "1    In the clandestine world of time travel, where...   \n",
       "2    In the year 2342, time travel had become a pop...   \n",
       "3    In the intricate labyrinth of time, where mome...   \n",
       "4    In the realm of temporal anomalies and audacio...   \n",
       "..                                                 ...   \n",
       "795  In the hushed tranquility of the celestial rea...   \n",
       "796  As I arrived at the pearly gates of Heaven, my...   \n",
       "797  In the ethereal realm, where clouds caressed t...   \n",
       "798  In the ethereal realm of the afterlife, I stoo...   \n",
       "799  In the vast expanse of the afterlife, I found ...   \n",
       "\n",
       "                                        common_vectors  \\\n",
       "0    [0, 2, 13, 1, 6, 1, 1, 2, 0, 1, 0, 0, 1, 3, 0,...   \n",
       "1    [0, 2, 17, 0, 10, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0...   \n",
       "2    [0, 2, 17, 0, 8, 0, 0, 0, 0, 1, 1, 3, 0, 0, 0,...   \n",
       "3    [0, 6, 11, 0, 7, 0, 0, 0, 0, 0, 2, 3, 0, 2, 0,...   \n",
       "4    [0, 0, 24, 0, 7, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0,...   \n",
       "..                                                 ...   \n",
       "795  [1, 2, 14, 0, 1, 0, 0, 1, 0, 3, 4, 0, 0, 0, 0,...   \n",
       "796  [0, 2, 13, 0, 7, 2, 2, 1, 0, 2, 2, 0, 0, 0, 0,...   \n",
       "797  [0, 3, 8, 0, 6, 0, 1, 1, 0, 1, 4, 3, 0, 1, 0, ...   \n",
       "798  [2, 2, 25, 0, 6, 1, 2, 4, 0, 5, 6, 0, 0, 0, 0,...   \n",
       "799  [0, 1, 14, 0, 4, 2, 3, 4, 0, 5, 2, 0, 0, 1, 0,...   \n",
       "\n",
       "                                      function_vectors  \n",
       "0    [1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "1    [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "2    [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, ...  \n",
       "..                                                 ...  \n",
       "795  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "796  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "797  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "798  [0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, ...  \n",
       "799  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, ...  \n",
       "\n",
       "[800 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_style_vectors = pd.DataFrame({\n",
    "    'prompt': common_df.prompt,\n",
    "    'response': common_df.response,\n",
    "    'common_vectors': common_df.SummaryVector,\n",
    "    'function_vectors': function_df.SummaryVector\n",
    "})\n",
    "\n",
    "gemini_style_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b92230",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_style_vectors.to_csv(\"gemini_style_vectors.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
