{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import LogLocator\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"function_words/oshea.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    function_words = [line.split()[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN = \"human\"\n",
    "\n",
    "GEMINI_10 = \"gemini-1.0-pro\"\n",
    "GEMINI_15 = \"gemini-1.5-pro-latest\"\n",
    "\n",
    "CLAUDE_SONNET = \"claude-3-sonnet-20240229\"\n",
    "CLAUDE_OPUS = \"claude-3-opus-20240229\"\n",
    "\n",
    "GPT_35 = \"gpt-3.5-turbo-0125\"\n",
    "GPT_40 = \"gpt-4-turbo-2024-04-09\"\n",
    "\n",
    "LLMS = [GEMINI_10, GEMINI_15, CLAUDE_SONNET, CLAUDE_OPUS, GPT_35, GPT_40]\n",
    "AUTHORS = [HUMAN] + LLMS\n",
    "\n",
    "REDDIT = \"reddit\"\n",
    "HEWLETT = \"hewlett\"\n",
    "DATASETS = [REDDIT, HEWLETT]\n",
    "\n",
    "PAIRS = []\n",
    "for i, author1 in enumerate(AUTHORS):\n",
    "    for author2 in AUTHORS[i + 1 :]:\n",
    "        PAIRS.append((author1, author2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for dataset in DATASETS:\n",
    "    for author in AUTHORS:\n",
    "        df_cur = pd.read_csv(f\"{dataset}/responses/{author}.csv\")\n",
    "        df_cur[\"dataset\"] = dataset\n",
    "        df_cur[\"author\"] = author\n",
    "        df.append(df_cur)\n",
    "df = pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZScoreTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, function_words):\n",
    "        self.function_words = function_words\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            use_idf=False, norm=None, tokenizer=word_tokenize, token_pattern=None\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Fit the vectorizer to the corpus\n",
    "        word_counts = self.vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "        # Save the function words and their indices if they are in the vocabulary\n",
    "        self.used_function_words = [\n",
    "            word for word in self.function_words if word in self.vectorizer.vocabulary_\n",
    "        ]\n",
    "        self.used_function_words_indices = [\n",
    "            self.vectorizer.vocabulary_[word] for word in self.used_function_words\n",
    "        ]\n",
    "\n",
    "        # Calculate the relative frequencies\n",
    "        relative_freqs = word_counts / word_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # Fit the z-score scaler\n",
    "        self.scaler.fit(relative_freqs)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, z_score=True):\n",
    "        # Transform the corpus into word counts\n",
    "        word_counts = self.vectorizer.transform(X).toarray()\n",
    "\n",
    "        # Calculate the relative frequencies\n",
    "        relative_freqs = word_counts / word_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "        if not z_score:\n",
    "            return relative_freqs[:, self.used_function_words_indices]\n",
    "\n",
    "        # Calculate the z-scores\n",
    "        return self.scaler.transform(relative_freqs)[\n",
    "            :, self.used_function_words_indices\n",
    "        ]\n",
    "\n",
    "    def get_used_function_words(self):\n",
    "        return self.used_function_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "author_groups = PAIRS + [LLMS, AUTHORS]\n",
    "\n",
    "for reducer, reducer_name in [(PCA, \"PCA\"), (TSNE, \"t-SNE\")]:\n",
    "    for authors in author_groups:\n",
    "        if len(authors) == 2:\n",
    "            filename = f\"figures/{reducer_name}/{authors[0]}_{authors[1]}.png\"\n",
    "        elif len(authors) == 6:\n",
    "            filename = f\"figures/{reducer_name}/all_llms.png\"\n",
    "        else:\n",
    "            filename = f\"figures/{reducer_name}/all_authors.png\"\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            continue\n",
    "\n",
    "        df_sampled = (\n",
    "            df[(df[\"author\"].isin(authors))]\n",
    "            .groupby([\"dataset\", \"author\", \"prompt_id\"])\n",
    "            .apply(lambda x: x.sample(10), include_groups=False)\n",
    "            .reset_index(drop=False)\n",
    "        )\n",
    "\n",
    "        z_scores_transformer = ZScoreTransformer(function_words)\n",
    "        z_scores = z_scores_transformer.fit_transform(df_sampled[\"text\"])\n",
    "\n",
    "        dim_reducer = reducer(n_components=2)\n",
    "        z_scores_reduced = dim_reducer.fit_transform(z_scores)\n",
    "\n",
    "        df_reduced = pd.DataFrame(\n",
    "            z_scores_reduced, columns=[f\"{reducer_name} 1\", f\"{reducer_name} 2\"]\n",
    "        )\n",
    "        df_reduced[\"author\"] = df_sampled[\"author\"]\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(\n",
    "            data=df_reduced, x=f\"{reducer_name} 1\", y=f\"{reducer_name} 2\", hue=\"author\"\n",
    "        )\n",
    "        plt.title(f\"{reducer_name} over function word embeddings\")\n",
    "        plt.legend(title=\"Author\")\n",
    "        plt.savefig(filename)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(df, authors, function_words, return_df_coefs=False):\n",
    "    df = df[df[\"author\"].isin(authors)]\n",
    "\n",
    "    # n_responses_per_author_per_prompt_per_dataset = 10\n",
    "    # df = df.groupby([\"author\", \"prompt_id\", \"dataset\"]).sample(\n",
    "    #     n_responses_per_author_per_prompt_per_dataset\n",
    "    # )\n",
    "\n",
    "    # Train-test split: 12/4 (2 prompts from each dataset in the test set)\n",
    "    test_indices = []\n",
    "    for dataset in DATASETS:\n",
    "        test_prompts = np.random.choice(8, 2, replace=False)\n",
    "        test_indices.append(\n",
    "            (df[\"dataset\"] == dataset) & (df[\"prompt_id\"].isin(test_prompts))\n",
    "        )\n",
    "    test_indices = pd.concat(test_indices, axis=1).any(axis=1)\n",
    "\n",
    "    df_test = df[test_indices].copy()\n",
    "    df_train = df[~test_indices].copy()\n",
    "\n",
    "    # Set up 6-fold cross-validation\n",
    "    train_indices_by_prompt = list(\n",
    "        df_train.groupby([\"dataset\", \"prompt_id\"]).indices.values()\n",
    "    )\n",
    "\n",
    "    cv_iterable = []\n",
    "    for _ in range(6):\n",
    "        val_indices = np.concatenate(train_indices_by_prompt[:2])\n",
    "        train_indices = np.concatenate(train_indices_by_prompt[2:])\n",
    "        cv_iterable.append((train_indices, val_indices))\n",
    "        # Cycle indices list\n",
    "        train_indices_by_prompt = (\n",
    "            train_indices_by_prompt[2:] + train_indices_by_prompt[:2]\n",
    "        )\n",
    "\n",
    "    # Use the ZScoreTransformer to get the z-scores\n",
    "    z_scores_transformer = ZScoreTransformer(function_words)\n",
    "    z_scores_train = z_scores_transformer.fit_transform(df_train[\"text\"])\n",
    "    z_scores_test = z_scores_transformer.transform(df_test[\"text\"])\n",
    "\n",
    "    param_grid = {\n",
    "        \"C\": [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0],\n",
    "        \"solver\": [\"lbfgs\", \"liblinear\"],\n",
    "    }\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        param_grid=param_grid,\n",
    "        cv=cv_iterable,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "    )\n",
    "\n",
    "    # Model training and prediction\n",
    "    model.fit(z_scores_train, df_train[\"author\"])\n",
    "    df_test[\"author_pred\"] = model.predict(z_scores_test)\n",
    "\n",
    "    if not return_df_coefs:\n",
    "        return df_test\n",
    "\n",
    "    # Logistic regression model coefficients\n",
    "    coefs = model.best_estimator_.coef_.squeeze()\n",
    "\n",
    "    # For multiclass, return the average of the absolute values of the coefficients\n",
    "    if len(authors) > 2:\n",
    "        coefs = np.mean(np.abs(coefs), axis=0)\n",
    "\n",
    "    used_function_words = z_scores_transformer.get_used_function_words()\n",
    "    df_coefs = pd.DataFrame({\"word\": used_function_words, \"coef\": coefs})\n",
    "    return df_test, df_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from json import dumps\n",
    "\n",
    "N_TRIALS = 10\n",
    "\n",
    "\n",
    "def process_pair(pair_trial):\n",
    "    (author1, author2), trial = pair_trial\n",
    "    df_test, df_coefs = classify(\n",
    "        df=df,\n",
    "        authors=[author1, author2],\n",
    "        function_words=function_words,\n",
    "        return_df_coefs=True,\n",
    "    )\n",
    "\n",
    "    accuracy = sum(df_test[\"author\"] == df_test[\"author_pred\"]) / len(df_test)\n",
    "    df_test_json = dumps(df_test.to_json(orient=\"records\"))\n",
    "    df_coefs_json = dumps(df_coefs.to_json(orient=\"records\"))\n",
    "\n",
    "    df_results = {\n",
    "        \"author1\": author1,\n",
    "        \"author2\": author2,\n",
    "        \"trial\": trial,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"df_test\": df_test_json,\n",
    "        \"df_coefs\": df_coefs_json,\n",
    "    }\n",
    "    return df_results\n",
    "\n",
    "\n",
    "results_filename = \"classification_results/pairwise_classification.csv\"\n",
    "if os.path.exists(results_filename):\n",
    "    df_results = pd.read_csv(results_filename)\n",
    "else:\n",
    "    # Run in parallel using joblib\n",
    "    pairs_trials = list(product(PAIRS, range(N_TRIALS)))\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_pair)(pair_trial) for pair_trial in tqdm(pairs_trials)\n",
    "    )\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(results_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_pivot = (\n",
    "    df_results[[\"author1\", \"author2\", \"accuracy\"]]\n",
    "    .groupby([\"author1\", \"author2\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .pivot(index=\"author1\", columns=\"author2\", values=\"accuracy\")\n",
    "    .reindex(index=AUTHORS, columns=AUTHORS)\n",
    ")\n",
    "\n",
    "classification_figname = \"figures/pairwise/classification/heatmap.png\"\n",
    "if not os.path.exists(classification_figname):\n",
    "    sns.heatmap(bin_pivot, annot=True, vmin=0.5, vmax=1.0)\n",
    "    plt.title(\"Binary Logistic Regression Classification Accuracies\")\n",
    "    plt.ylabel(\"Author 1\")\n",
    "    plt.xlabel(\"Author 2\")\n",
    "    plt.savefig(classification_figname, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from io import StringIO\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_cms = []\n",
    "for _, (author1, author2, trial, accuracy, df_test, df_coefs) in df_results.iterrows():\n",
    "    df_test = pd.read_json(StringIO(loads(df_test)))\n",
    "\n",
    "    cm = confusion_matrix(\n",
    "        df_test[\"author\"],\n",
    "        df_test[\"author_pred\"],\n",
    "        normalize=\"true\",\n",
    "        labels=[author1, author2],\n",
    "    )\n",
    "\n",
    "    zero_zero = cm[0, 0]\n",
    "    zero_one = cm[0, 1]\n",
    "    one_zero = cm[1, 0]\n",
    "    one_one = cm[1, 1]\n",
    "\n",
    "    df_cms.append(\n",
    "        {\n",
    "            \"author1\": author1,\n",
    "            \"author2\": author2,\n",
    "            \"zero_zero\": zero_zero,\n",
    "            \"zero_one\": zero_one,\n",
    "            \"one_zero\": one_zero,\n",
    "            \"one_one\": one_one,\n",
    "        }\n",
    "    )\n",
    "df_cms = pd.DataFrame(df_cms)\n",
    "df_cms = df_cms.groupby([\"author1\", \"author2\"]).mean().reset_index()\n",
    "\n",
    "for _, (author1, author2, z_z, z_o, o_z, o_o) in df_cms.iterrows():\n",
    "    classification_figname = (\n",
    "        f\"figures/pairwise/classification/confusion_matrices/{author1}_{author2}.png\"\n",
    "    )\n",
    "    if os.path.exists(classification_figname):\n",
    "        continue\n",
    "\n",
    "    authors = [author1, author2]\n",
    "    cm = np.array([[z_z, z_o], [o_z, o_o]])\n",
    "    cm = pd.DataFrame(cm, index=authors, columns=authors)\n",
    "\n",
    "    sns.heatmap(cm, annot=True, vmin=0, vmax=1)\n",
    "    plt.title(\"Average Confusion Matrix for Binary Logistic Regression\")\n",
    "    plt.ylabel(\"True author\")\n",
    "    plt.xlabel(\"Predicted author\")\n",
    "    plt.savefig(classification_figname, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = df[\"author\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined confusion matrix (7x7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pairwise_figname = (\n",
    "    \"figures/pairwise/classification/confusion_matrices/combined.png\"\n",
    ")\n",
    "if True:  # not os.path.exists(combined_pairwise_figname):\n",
    "    i_as_i = df_cms.pivot(index=\"author1\", columns=\"author2\", values=\"zero_one\")\n",
    "    i_as_i[\"human\"] = np.nan\n",
    "    i_as_i = i_as_i.reindex(AUTHORS)\n",
    "    i_as_i = i_as_i[AUTHORS]\n",
    "\n",
    "    j_as_j = df_cms.pivot(index=\"author1\", columns=\"author2\", values=\"one_zero\")\n",
    "    j_as_j[\"human\"] = np.nan\n",
    "    j_as_j = j_as_j.reindex(AUTHORS)\n",
    "    j_as_j = j_as_j[AUTHORS]\n",
    "    j_as_j = j_as_j.T\n",
    "\n",
    "    combined = i_as_i.add(j_as_j, fill_value=0)\n",
    "\n",
    "    author1_df = df_cms[[\"author1\", \"zero_zero\"]].rename(\n",
    "        columns={\"author1\": \"author\", \"zero_zero\": \"accuracy\"}\n",
    "    )\n",
    "    author2_df = df_cms[[\"author2\", \"one_one\"]].rename(\n",
    "        columns={\"author2\": \"author\", \"one_one\": \"accuracy\"}\n",
    "    )\n",
    "    diagonal = pd.concat([author1_df, author2_df])\n",
    "    diagonal = diagonal.groupby(\"author\").mean().reindex(AUTHORS)[\"accuracy\"]\n",
    "\n",
    "    combined = combined.values\n",
    "    np.fill_diagonal(combined, diagonal)\n",
    "    combined = pd.DataFrame(combined, index=AUTHORS, columns=AUTHORS)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(combined, annot=True, fmt=\".2f\", vmin=0, vmax=1)\n",
    "    plt.title(\"Combined Confusion Matrix for Binary Logistic Regression\")\n",
    "    plt.ylabel(\"True Author\")\n",
    "    plt.xlabel(\"Predicated Author\")\n",
    "    plt.savefig(\n",
    "        \"figures/pairwise/classification/confusion_matrices/combined.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humans and LLMs confused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM experiments ranked by the frequency of confusing the LLM for the human:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "author2\n",
       "claude-3-sonnet-20240229    0.25250\n",
       "claude-3-opus-20240229      0.21050\n",
       "gpt-3.5-turbo-0125          0.14800\n",
       "gemini-1.0-pro              0.08400\n",
       "gpt-4-turbo-2024-04-09      0.07775\n",
       "gemini-1.5-pro-latest       0.05475\n",
       "Name: one_zero, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_experiments = (\n",
    "    df_cms[df_cms[\"author1\"] == HUMAN].drop(columns=\"author1\").groupby(\"author2\").mean()\n",
    ")\n",
    "\n",
    "print(\"LLM experiments ranked by the frequency of confusing the LLM for the human:\")\n",
    "human_experiments[\"one_zero\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM experiments ranked by the frequency of confusing the human for the LLM:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "author2\n",
       "claude-3-opus-20240229      0.09900\n",
       "claude-3-sonnet-20240229    0.08775\n",
       "gpt-4-turbo-2024-04-09      0.06875\n",
       "gemini-1.5-pro-latest       0.06475\n",
       "gpt-3.5-turbo-0125          0.03375\n",
       "gemini-1.0-pro              0.01250\n",
       "Name: zero_one, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"LLM experiments ranked by the frequency of confusing the human for the LLM:\")\n",
    "human_experiments[\"zero_one\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average word coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from io import StringIO\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_coefs_list = []\n",
    "for i, (author1, author2, trial, accuracy, df_test, df_coefs) in df_results.iterrows():\n",
    "    df_coefs = pd.read_json(StringIO(loads(df_coefs)))\n",
    "    df_coefs[\"i\"] = i\n",
    "    df_coefs = df_coefs.pivot(index=\"i\", columns=\"word\", values=\"coef\")\n",
    "    df_coefs[\"author1\"] = author1\n",
    "    df_coefs[\"author2\"] = author2\n",
    "    df_coefs_list.append(df_coefs)\n",
    "\n",
    "df_coefs_list = pd.concat(df_coefs_list).replace(np.nan, 0)\n",
    "df_coefs_list = df_coefs_list.groupby([\"author1\", \"author2\"]).mean().abs()\n",
    "df_coefs_list = df_coefs_list.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "in             0.256229\n",
       "here           0.246231\n",
       "and            0.237781\n",
       "an             0.226464\n",
       "of             0.214341\n",
       "a              0.207266\n",
       "is             0.204516\n",
       "as             0.202178\n",
       "to             0.192250\n",
       "this           0.168080\n",
       "despite        0.162987\n",
       "which          0.162064\n",
       "with           0.158224\n",
       "that           0.149843\n",
       "moreover       0.149747\n",
       "was            0.148755\n",
       "not            0.144959\n",
       "may            0.141715\n",
       "furthermore    0.141356\n",
       "when           0.140737\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coefs_list.mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from json import dumps\n",
    "\n",
    "\n",
    "mc_results_filename = \"classification_results/multiclass_classification.csv\"\n",
    "\n",
    "if os.path.exists(mc_results_filename):\n",
    "    df_mc_results = pd.read_csv(mc_results_filename)\n",
    "else:\n",
    "    mc_results = []\n",
    "    for _ in tqdm(range(N_TRIALS)):\n",
    "        df_test, df_coefs = classify(\n",
    "            df=df,\n",
    "            authors=AUTHORS,\n",
    "            function_words=function_words,\n",
    "            return_df_coefs=True,\n",
    "        )\n",
    "\n",
    "        df_test_json = dumps(df_test.to_json(orient=\"records\"))\n",
    "        df_coefs_json = dumps(df_coefs.to_json(orient=\"records\"))\n",
    "\n",
    "        mc_results.append(\n",
    "            {\n",
    "                \"df_test\": df_test_json,\n",
    "                \"df_coefs\": df_coefs_json,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_mc_results = pd.DataFrame(mc_results)\n",
    "    df_mc_results.to_csv(mc_results_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = []\n",
    "for _, (df_test, _) in df_mc_results.iterrows():\n",
    "    df_test = pd.read_json(StringIO(loads(df_test)))\n",
    "    cm = confusion_matrix(\n",
    "        df_test[\"author\"], df_test[\"author_pred\"], normalize=\"true\", labels=AUTHORS\n",
    "    )\n",
    "    cms.append(cm)\n",
    "multi_cm = np.mean(cms, axis=0)\n",
    "\n",
    "classification_figname = \"figures/multiclass/classification/confusion_matrix.png\"\n",
    "if not os.path.exists(classification_figname):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        multi_cm,\n",
    "        annot=True,\n",
    "        xticklabels=AUTHORS,\n",
    "        yticklabels=AUTHORS,\n",
    "        fmt=\".2f\",\n",
    "    )\n",
    "    plt.title(\"Multiclass Classification Confusion Matrix\")\n",
    "    plt.ylabel(\"True author\")\n",
    "    plt.xlabel(\"Predicted author\")\n",
    "    plt.savefig(classification_figname, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average word coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from io import StringIO\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_coefs_list = []\n",
    "for _, (_, df_coefs) in df_mc_results.iterrows():\n",
    "    df_coefs = pd.read_json(StringIO(loads(df_coefs)))\n",
    "    df_coefs[\"i\"] = i\n",
    "    df_coefs = df_coefs.pivot(index=\"i\", columns=\"word\", values=\"coef\")\n",
    "    df_coefs_list.append(df_coefs)\n",
    "\n",
    "df_coefs_list = pd.concat(df_coefs_list).replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "here       0.268697\n",
       "a          0.248612\n",
       "in         0.244271\n",
       "and        0.238381\n",
       "an         0.227587\n",
       "of         0.224629\n",
       "is         0.209168\n",
       "as         0.205005\n",
       "to         0.201880\n",
       "this       0.182059\n",
       "which      0.181930\n",
       "the        0.174612\n",
       "that       0.170505\n",
       "their      0.169423\n",
       "it         0.164873\n",
       "may        0.161354\n",
       "how        0.160643\n",
       "despite    0.159006\n",
       "when       0.158213\n",
       "not        0.154064\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_coef_mc = df_coefs_list.mean().sort_values(ascending=False).head(20)\n",
    "highest_coef_mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_figname = \"figures/word_frequencies/pronouns_heatmap.png\"\n",
    "pronouns = [\n",
    "    \"he\",\n",
    "    \"him\",\n",
    "    \"his\",\n",
    "    \"himself\",\n",
    "    \"she\",\n",
    "    \"her\",\n",
    "    \"herself\",\n",
    "    \"they\",\n",
    "    \"them\",\n",
    "    \"their\",\n",
    "    \"themselves\",\n",
    "]\n",
    "\n",
    "# Select the words with the highest coefficients in the multiclass classification\n",
    "high_coef_figname = \"figures/word_frequencies/high_coef_words_heatmap.png\"\n",
    "highest_coef_mc_words = list(highest_coef_mc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_tuples = [\n",
    "    (\"Pronouns\", pronouns, pronoun_figname),\n",
    "    (\"High LR Coefficient Words\", highest_coef_mc_words, high_coef_figname),\n",
    "]\n",
    "\n",
    "for title, words, figname in word_list_tuples:\n",
    "    if os.path.exists(figname):\n",
    "        continue\n",
    "\n",
    "    all_word_frequencies = []\n",
    "    for word in words:\n",
    "        word_frequencies = {}\n",
    "        for author in AUTHORS:\n",
    "            author_df = df[df[\"author\"] == author]\n",
    "            word_counts = author_df[\"text\"].str.count(word)\n",
    "            word_freq = word_counts / author_df[\"text\"].str.split().apply(len)\n",
    "            word_frequencies[author] = word_freq.mean()\n",
    "        all_word_frequencies.append(word_frequencies)\n",
    "\n",
    "    frequencies_df = pd.DataFrame(all_word_frequencies, index=words)\n",
    "    frequencies_df = frequencies_df.div(frequencies_df[\"human\"], axis=0)\n",
    "    plt.figure(figsize=(6, 8))\n",
    "    sns.heatmap(\n",
    "        frequencies_df.drop(columns=\"human\"),\n",
    "        annot=True,\n",
    "        fmt=\".3f\",\n",
    "        norm=LogNorm(vmin=0.25, vmax=4),\n",
    "        cbar_kws={\"format\": \"%.2g\", \"ticks\": [0.25, 0.5, 1, 2, 4]},\n",
    "        cmap=sns.color_palette(\"vlag_r\", as_cmap=True),\n",
    "    )\n",
    "    plt.title(f\"LLM/Human Frequency Ratios over {title}\")\n",
    "    plt.xlabel(\"Author\")\n",
    "    plt.ylabel(\"Word\")\n",
    "    plt.savefig(figname, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dendrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 3. Average feature vector\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# By using the average feature vector from the z-score transformer for each author\u001b[39;00m\n\u001b[1;32m     14\u001b[0m z_scores_transformer \u001b[38;5;241m=\u001b[39m ZScoreTransformer(function_words)\n\u001b[0;32m---> 15\u001b[0m z_scores \u001b[38;5;241m=\u001b[39m \u001b[43mz_scores_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m z_scores_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cosine_similarity(\n\u001b[1;32m     17\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(z_scores, index\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mZScoreTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Fit the vectorizer to the corpus\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     word_counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Save the function words and their indices if they are in the vocabulary\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mused_function_words \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     15\u001b[0m         word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mvocabulary_\n\u001b[1;32m     16\u001b[0m     ]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2090\u001b[0m )\n\u001b[0;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:110\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/__init__.py:107\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1281\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1341\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1341\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1329\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[1;32m   1328\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (sentence\u001b[38;5;241m.\u001b[39mstart, sentence\u001b[38;5;241m.\u001b[39mstop)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1459\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;124;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;124;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;124;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m realign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence1, sentence2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(slices):\n\u001b[1;32m   1460\u001b[0m     sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(sentence1\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m realign, sentence1\u001b[38;5;241m.\u001b[39mstop)\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentence2:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:324\u001b[0m, in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (prev, el)\n\u001b[1;32m    326\u001b[0m     prev \u001b[38;5;241m=\u001b[39m el\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1432\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1430\u001b[0m last_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_potential_end_contexts(text):\n\u001b[0;32m-> 1432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_contains_sentbreak\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1433\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(last_break, match\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m   1434\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_tok\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1435\u001b[0m             \u001b[38;5;66;03m# next sentence starts after whitespace\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1480\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.text_contains_sentbreak\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;124;03mReturns True if the given text includes a sentence break.\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# used to ignore last token\u001b[39;00m\n\u001b[0;32m-> 1480\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_annotate_tokens(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenize_words(text)):\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1622\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._annotate_second_pass\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_annotate_second_pass\u001b[39m(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m, tokens: Iterator[PunktToken]\n\u001b[1;32m   1616\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[PunktToken]:\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;124;03m    Performs a token-based classification (section 4) over the given\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;124;03m    tokens, making use of the orthographic heuristic (4.1.1), collocation\u001b[39;00m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;124;03m    heuristic (4.1.2) and frequent sentence starter heuristic (4.1.3).\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token1, token2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(tokens):\n\u001b[1;32m   1623\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_second_pass_annotation(token1, token2)\n\u001b[1;32m   1624\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m token1\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:321\u001b[0m, in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    319\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:603\u001b[0m, in \u001b[0;36mPunktBaseClass._annotate_first_pass\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_annotate_first_pass\u001b[39m(\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m, tokens: Iterator[PunktToken]\n\u001b[1;32m    586\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[PunktToken]:\n\u001b[1;32m    587\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m    Perform the first pass of annotation, which makes decisions\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m    based purely based on the word type of each word:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m      - ellipsis_toks: The indices of all ellipsis marks.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m aug_tok \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_pass_annotation(aug_tok)\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m aug_tok\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:565\u001b[0m, in \u001b[0;36mPunktBaseClass._tokenize_words\u001b[0;34m(self, plaintext)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m plaintext\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[0;32m--> 565\u001b[0m         line_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lang_vars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m             tok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(line_toks)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/llm-style-VrzDc8fp-py3.10/lib/python3.10/site-packages/nltk/tokenize/punkt.py:267\u001b[0m, in \u001b[0;36mPunktLanguageVars.word_tokenize\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_re_word_tokenizer \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_word_tokenize_fmt\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;241m%\u001b[39m {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m             re\u001b[38;5;241m.\u001b[39mUNICODE \u001b[38;5;241m|\u001b[39m re\u001b[38;5;241m.\u001b[39mVERBOSE,\n\u001b[1;32m    264\u001b[0m         )\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_re_word_tokenizer\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Tokenize a string to split off punctuation other than periods\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_word_tokenizer_re()\u001b[38;5;241m.\u001b[39mfindall(s)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Binary classification\n",
    "# By turning the binary classification results into a similarity matrix\n",
    "np.fill_diagonal(bin_pivot.values, 1)\n",
    "binary_distance = 1 - bin_pivot.fillna(bin_pivot.T)\n",
    "\n",
    "# 2. Multiclass classification\n",
    "# By using the distribution of predictions in the multiclass LR as a feature vector for each author\n",
    "multiclass_distance = 1 - cosine_similarity(multi_cm)\n",
    "\n",
    "# 3. Average feature vector\n",
    "# By using the average feature vector from the z-score transformer for each author\n",
    "z_scores_transformer = ZScoreTransformer(function_words)\n",
    "z_scores = z_scores_transformer.fit_transform(df[\"text\"])\n",
    "z_scores_distance = 1 - cosine_similarity(\n",
    "    pd.DataFrame(z_scores, index=df[\"author\"])\n",
    "    .groupby(\"author\")\n",
    "    .mean()\n",
    "    .reindex(AUTHORS)\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # From https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "distance_matrices = {\n",
    "    \"Binary Classification\": binary_distance,\n",
    "    \"Multiclass Classification\": multiclass_distance,\n",
    "    \"Average Feature Vector\": z_scores_distance,\n",
    "}\n",
    "\n",
    "for title, distance_matrix in distance_matrices.items():\n",
    "    for linkage in [\"single\", \"average\", \"complete\"]:\n",
    "        figname = f\"figures/dendrograms/{title.replace(' ', '-').lower()}_{linkage}.png\"\n",
    "        if os.path.exists(figname):\n",
    "            continue\n",
    "\n",
    "        agg = AgglomerativeClustering(\n",
    "            n_clusters=1,\n",
    "            metric=\"precomputed\",\n",
    "            linkage=linkage,\n",
    "            compute_distances=True,\n",
    "        )\n",
    "\n",
    "        agg.fit(distance_matrix)\n",
    "\n",
    "        plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "        plot_dendrogram(agg, labels=AUTHORS, leaf_font_size=10)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.savefig(figname, bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized = z_scores_transformer.fit(df[\"text\"]).transform(df[\"text\"], z_score=False)\n",
    "\n",
    "# Ensure: z-scores == scaled(unnormalized feature vectors)\n",
    "assert np.max(StandardScaler().fit_transform(unnormalized) - z_scores) < 1e-10\n",
    "z_scores_df = pd.DataFrame(z_scores, index=df[\"author\"])\n",
    "unnormalized_df = pd.DataFrame(unnormalized, index=df[\"author\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Z-Scores</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Unnormalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>element-wise-average distance</th>\n",
       "      <th>euclidian distance</th>\n",
       "      <th>cosine distance</th>\n",
       "      <th>element-wise-average distance</th>\n",
       "      <th>euclidian distance</th>\n",
       "      <th>cosine distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.447142</td>\n",
       "      <td>13.155051</td>\n",
       "      <td>0.903062</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>0.159059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-sonnet-20240229</th>\n",
       "      <td>0.471056</td>\n",
       "      <td>14.340473</td>\n",
       "      <td>0.882782</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.056545</td>\n",
       "      <td>0.168349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.0-pro</th>\n",
       "      <td>0.380644</td>\n",
       "      <td>12.503603</td>\n",
       "      <td>0.797152</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.056127</td>\n",
       "      <td>0.142965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-pro-latest</th>\n",
       "      <td>0.381186</td>\n",
       "      <td>11.998472</td>\n",
       "      <td>0.809691</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>0.119705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.424417</td>\n",
       "      <td>14.329751</td>\n",
       "      <td>0.813542</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.063614</td>\n",
       "      <td>0.164636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo-2024-04-09</th>\n",
       "      <td>0.430161</td>\n",
       "      <td>13.255438</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.045552</td>\n",
       "      <td>0.114088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>0.599044</td>\n",
       "      <td>20.437783</td>\n",
       "      <td>0.771308</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.242741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Z-Scores                     \\\n",
       "                         element-wise-average distance euclidian distance   \n",
       "author                                                                      \n",
       "claude-3-opus-20240229                        0.447142          13.155051   \n",
       "claude-3-sonnet-20240229                      0.471056          14.340473   \n",
       "gemini-1.0-pro                                0.380644          12.503603   \n",
       "gemini-1.5-pro-latest                         0.381186          11.998472   \n",
       "gpt-3.5-turbo-0125                            0.424417          14.329751   \n",
       "gpt-4-turbo-2024-04-09                        0.430161          13.255438   \n",
       "human                                         0.599044          20.437783   \n",
       "\n",
       "                                                          Unnormalized  \\\n",
       "                         cosine distance element-wise-average distance   \n",
       "author                                                                   \n",
       "claude-3-opus-20240229          0.903062                      0.001385   \n",
       "claude-3-sonnet-20240229        0.882782                      0.001420   \n",
       "gemini-1.0-pro                  0.797152                      0.001317   \n",
       "gemini-1.5-pro-latest           0.809691                      0.001204   \n",
       "gpt-3.5-turbo-0125              0.813542                      0.001443   \n",
       "gpt-4-turbo-2024-04-09          0.838384                      0.001171   \n",
       "human                           0.771308                      0.001717   \n",
       "\n",
       "                                                             \n",
       "                         euclidian distance cosine distance  \n",
       "author                                                       \n",
       "claude-3-opus-20240229             0.054888        0.159059  \n",
       "claude-3-sonnet-20240229           0.056545        0.168349  \n",
       "gemini-1.0-pro                     0.056127        0.142965  \n",
       "gemini-1.5-pro-latest              0.048869        0.119705  \n",
       "gpt-3.5-turbo-0125                 0.063614        0.164636  \n",
       "gpt-4-turbo-2024-04-09             0.045552        0.114088  \n",
       "human                              0.067824        0.242741  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from numpy import abs, mean\n",
    "\n",
    "\n",
    "def variability(feature_vectors: pd.DataFrame, distance_metric: str) -> pd.Series:\n",
    "    grouped = feature_vectors.groupby(\"author\")\n",
    "\n",
    "    if distance_metric == \"element-wise-average\":\n",
    "        # For each author: compute the mean distance from the centroid over the elements of the feature vectors\n",
    "        return grouped.apply(lambda x: mean(abs(x - x.mean())))\n",
    "\n",
    "    elif distance_metric == \"euclidian\":\n",
    "        # For each author: compute the average euclidian distance from the centroid\n",
    "        return grouped.apply(lambda x: norm(x - x.mean(), axis=1).mean())\n",
    "    elif distance_metric == \"cosine\":\n",
    "        # For each author: compute the average cosine distance from the centroid\n",
    "        return grouped.apply(lambda x: 1 - cosine_similarity(x, [x.mean()]).mean())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid distance metric\")\n",
    "\n",
    "    # Return a series with index as author and value as variability\n",
    "\n",
    "\n",
    "distance_metrics = [\"element-wise-average\", \"euclidian\", \"cosine\"]\n",
    "feature_vectors = {\"Z-Scores\": z_scores_df, \"Unnormalized\": unnormalized_df}\n",
    "\n",
    "results = {}\n",
    "for feature_name, vectors_df in feature_vectors.items():\n",
    "    for metric in distance_metrics:\n",
    "        key = (feature_name, metric + \" distance\")\n",
    "        results[key] = variability(vectors_df, metric)\n",
    "\n",
    "variability_df = pd.DataFrame(results)\n",
    "variability_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
