{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use min(8, 9) = 8 prompts, so both corpuses have the same number of prompts\n",
    "n_prompts = 8\n",
    "# We use the longest n_samples_per_prompt samples for each prompt, measured by number of words\n",
    "n_samples_per_prompt = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_0 = np.concatenate([[\"prompt_id\", \"text\"], [\"bert\"] * 768])\n",
    "index_1 = np.concatenate([[\"prompt_id\", \"text\"], [i for i in range(768)]])\n",
    "index = pd.MultiIndex.from_arrays([index_0, index_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for name in [\"train\", \"test\", \"valid\"]:\n",
    "    with open(\"reddit/writingPrompts/\" + name + \".wp_source\") as f_prompts:\n",
    "        prompts = f_prompts.readlines()\n",
    "    with open(\"reddit/writingPrompts/\" + name + \".wp_target\") as f_responses:\n",
    "        texts = f_responses.readlines()\n",
    "    assert len(prompts) == len(texts)\n",
    "    pairs.extend(list(zip(prompts, texts)))\n",
    "df_reddit = pd.DataFrame(pairs, columns=[\"prompt\", \"text\"])\n",
    "df_reddit = df_reddit[~df_reddit[\"prompt\"].str.contains(\"hitler\", case=False)]\n",
    "df_reddit = df_reddit.drop_duplicates(subset=[\"text\"])\n",
    "df_reddit = df_reddit[\n",
    "    df_reddit[\"prompt\"].isin(df_reddit[\"prompt\"].value_counts().index[:n_prompts])\n",
    "]\n",
    "df_reddit[\"prompt_id\"] = df_reddit[\"prompt\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Get the longest n_samples responses for each prompt\n",
    "df_reddit[\"text_len\"] = df_reddit[\"text\"].apply(lambda x: len(str.split(x)))\n",
    "df_reddit = (\n",
    "    df_reddit.groupby(\"prompt_id\")\n",
    "    .apply(lambda x: x.nlargest(n_samples_per_prompt, \"text_len\"), include_groups=False)\n",
    "    .reset_index(level=0, drop=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Break prompt into prompt and and prompt_tag\n",
    "df_reddit[\"prompt_tag\"] = (\n",
    "    df_reddit[\"prompt\"]\n",
    "    .str.split(\" \\]\", n=1)\n",
    "    .str[0]\n",
    "    .replace(\"\\[\", \"\", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "df_reddit[\"prompt\"] = df_reddit[\"prompt\"].str.split(\" \\]\", n=1).str[1].str.strip()\n",
    "df_reddit[\"prompt\"] = \"Prompt\\n\" + df_reddit[\"prompt\"]\n",
    "df_reddit[\"prompt_id\"] = df_reddit[\"prompt\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit_prompts = (\n",
    "    df_reddit[[\"prompt_id\", \"prompt\", \"prompt_tag\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"prompt_id\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "def modify_prompt(prompt):\n",
    "    prompt = prompt.split(\"\\n\")[1]\n",
    "    return \"Write a response the following creative writing prompt:\\n\" + prompt\n",
    "\n",
    "\n",
    "df_reddit_prompts[\"prompt\"] = df_reddit_prompts[\"prompt\"].apply(modify_prompt)\n",
    "\n",
    "df_reddit_prompts.to_csv(\"reddit_prompts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit = df_reddit[[\"prompt_id\", \"text\"]]\n",
    "df_reddit = df_reddit.sort_values(\"prompt_id\").reset_index(drop=True)\n",
    "df_reddit.to_csv(\"reddit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "WP: Writing Prompt\n",
    "SP: Simple Prompt\n",
    "EU: Established Universe\n",
    "CW: Constrained Writing\n",
    "TT: Theme Thursday\n",
    "PM: Prompt Me\n",
    "MP: Media Prompt\n",
    "IP: Image Prompt\n",
    "PI: Prompt Inspired\n",
    "OT: Off Topic\n",
    "* OT as an Advertisement!\n",
    "RF: Reality Fiction\n",
    "```\n",
    "\n",
    "https://www.reddit.com/r/WritingPrompts/wiki/how_to_tag_prompts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Write a response the following creative writin...</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Write a response the following creative writin...</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Write a response the following creative writin...</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Write a response the following creative writin...</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Write a response the following creative writin...</td>\n",
       "      <td>CW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Write a response the following creative writin...</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Write a response the following creative writin...</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Write a response the following creative writin...</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id                                             prompt prompt_tag\n",
       "0          0  Write a response the following creative writin...         WP\n",
       "1          1  Write a response the following creative writin...         WP\n",
       "2          2  Write a response the following creative writin...         WP\n",
       "3          3  Write a response the following creative writin...         WP\n",
       "4          4  Write a response the following creative writin...         CW\n",
       "5          5  Write a response the following creative writin...         WP\n",
       "6          6  Write a response the following creative writin...         WP\n",
       "7          7  Write a response the following creative writin...         WP"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>`` We left them there to study ! '' Proclaimed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>“ I suggest we initiate protocol Zestraol ” &lt;n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Our War Council was surprised when these Human...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>`` Drax , the Slovians have taken E13-49e , 4t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>`` They 've taken Marin , sir . '' &lt;newline&gt; &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>7</td>\n",
       "      <td>I 'd see her walking down the hall , her hair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>7</td>\n",
       "      <td>Wait . &lt;newline&gt; &lt;newline&gt; Doubt was settling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>7</td>\n",
       "      <td>It started as a chauvinistic affair meant to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>7</td>\n",
       "      <td>Izzard stalked through the once slicked stone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>7</td>\n",
       "      <td>He said he loved her and he wanted her , so th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                               text\n",
       "0            0  `` We left them there to study ! '' Proclaimed...\n",
       "1            0  “ I suggest we initiate protocol Zestraol ” <n...\n",
       "2            0  Our War Council was surprised when these Human...\n",
       "3            0  `` Drax , the Slovians have taken E13-49e , 4t...\n",
       "4            0  `` They 've taken Marin , sir . '' <newline> <...\n",
       "..         ...                                                ...\n",
       "795          7  I 'd see her walking down the hall , her hair ...\n",
       "796          7  Wait . <newline> <newline> Doubt was settling ...\n",
       "797          7  It started as a chauvinistic affair meant to m...\n",
       "798          7  Izzard stalked through the once slicked stone ...\n",
       "799          7  He said he loved her and he wanted her , so th...\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the responses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     800.00000\n",
       "mean      695.49625\n",
       "std       514.91980\n",
       "min       121.00000\n",
       "25%       290.00000\n",
       "50%       520.00000\n",
       "75%       932.25000\n",
       "max      2594.00000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of words in the responses:\")\n",
    "df_reddit[\"text\"].apply(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hewlett\n",
    "\n",
    "https://www.kaggle.com/competitions/asap-aes/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hewlett_prompts_dir = \"hewlett/prompts\"\n",
    "\n",
    "prompts = []\n",
    "for file in os.listdir(hewlett_prompts_dir):\n",
    "    with open(hewlett_prompts_dir + \"/\" + file) as f:\n",
    "        prompt = f.read()\n",
    "    prompts.append((int(file.split(\".\")[0]) - 1, prompt))\n",
    "\n",
    "df_hewlett_prompts = pd.DataFrame(prompts, columns=[\"prompt_id\", \"prompt\"])\n",
    "df_hewlett_prompts[\"prompt_tag\"] = df_hewlett_prompts[\"prompt\"].str.contains(\n",
    "    \"Source Essay\"\n",
    ")\n",
    "df_hewlett_prompts[\"prompt_tag\"] = df_hewlett_prompts[\"prompt_tag\"].replace(\n",
    "    {True: \"source dependent responses\", False: \"persuasive / narrative / expository\"}\n",
    ")\n",
    "df_hewlett_prompts = df_hewlett_prompts.sort_values(\"prompt_id\").reset_index(drop=True)\n",
    "df_hewlett_prompts.to_csv(\"hewlett_prompts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hewlett_dir = \"hewlett\"\n",
    "\n",
    "filenames = [\n",
    "    \"training_set_rel3.tsv\",\n",
    "    \"valid_set.tsv\",\n",
    "    \"test_set.tsv\",\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(f\"{hewlett_dir}/{filename}\", sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "    df = df[[\"essay_set\", \"essay\"]]\n",
    "    df.rename(columns={\"essay_set\": \"prompt_id\", \"essay\": \"text\"}, inplace=True)\n",
    "    df[\"prompt_id\"] = df[\"prompt_id\"].astype(int).apply(lambda x: x - 1)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Don't need to remove the responses of any prompts because there are 8 distinct prompts in this dataset\n",
    "df_hewlett = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_hewlett = df_hewlett[df_hewlett[\"text\"] != \"\"]\n",
    "df_hewlett = df_hewlett.dropna()\n",
    "df_hewlett = df_hewlett.drop_duplicates()\n",
    "\n",
    "# Get the longest n_samples responses for each prompt\n",
    "df_hewlett[\"text_len\"] = df_hewlett[\"text\"].apply(lambda x: len(str.split(x)))\n",
    "df_hewlett = (\n",
    "    df_hewlett.groupby(\"prompt_id\")\n",
    "    .apply(lambda x: x.nlargest(n_samples_per_prompt, \"text_len\"), include_groups=False)\n",
    "    .reset_index(level=0, drop=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_hewlett = df_hewlett[[\"prompt_id\", \"text\"]]\n",
    "\n",
    "df_hewlett.to_csv(\"hewlett.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Prompt\\nMore and more people use computers, bu...</td>\n",
       "      <td>persuasive / narrative / expository</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Prompt\\nCensorship in the Libraries\\n\"All of u...</td>\n",
       "      <td>persuasive / narrative / expository</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Source Essay\\nROUGH ROAD AHEAD: Do Not Exceed ...</td>\n",
       "      <td>source dependent responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Source Essay\\nWinter Hibiscus by Minfong Ho\\nS...</td>\n",
       "      <td>source dependent responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Source Essay\\nNarciso Rodriguez\\nfrom Home: Th...</td>\n",
       "      <td>source dependent responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Source Essay\\nThe Mooring Mast\\nby Marcia Amid...</td>\n",
       "      <td>source dependent responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Prompt\\nWrite about patience. Being patient me...</td>\n",
       "      <td>persuasive / narrative / expository</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Prompt\\nWe all understand the benefits of laug...</td>\n",
       "      <td>persuasive / narrative / expository</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id                                             prompt  \\\n",
       "0          0  Prompt\\nMore and more people use computers, bu...   \n",
       "1          1  Prompt\\nCensorship in the Libraries\\n\"All of u...   \n",
       "2          2  Source Essay\\nROUGH ROAD AHEAD: Do Not Exceed ...   \n",
       "3          3  Source Essay\\nWinter Hibiscus by Minfong Ho\\nS...   \n",
       "4          4  Source Essay\\nNarciso Rodriguez\\nfrom Home: Th...   \n",
       "5          5  Source Essay\\nThe Mooring Mast\\nby Marcia Amid...   \n",
       "6          6  Prompt\\nWrite about patience. Being patient me...   \n",
       "7          7  Prompt\\nWe all understand the benefits of laug...   \n",
       "\n",
       "                            prompt_tag  \n",
       "0  persuasive / narrative / expository  \n",
       "1  persuasive / narrative / expository  \n",
       "2           source dependent responses  \n",
       "3           source dependent responses  \n",
       "4           source dependent responses  \n",
       "5           source dependent responses  \n",
       "6  persuasive / narrative / expository  \n",
       "7  persuasive / narrative / expository  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hewlett_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My standing postion on this cause is that comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@ORGANIZATION1, @CAPS1? Are you there?\" \"@CAPS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Dear The @CAPS1 newspaper, @CAPS2 in front of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Dear @CAPS1 Society: Computers are perhaps one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Dear @ORGANIZATION1, The creation of computers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>7</td>\n",
       "      <td>We couldn't control our selves, our eyes wate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>7</td>\n",
       "      <td>It all started at the play ground @CAPS9 me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>7</td>\n",
       "      <td>For my family laughter is important to us bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>7</td>\n",
       "      <td>Laughter, one of the greatest gifts in life. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>7</td>\n",
       "      <td>Why is it that people can look back at someth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                               text\n",
       "0            0  My standing postion on this cause is that comp...\n",
       "1            0  @ORGANIZATION1, @CAPS1? Are you there?\" \"@CAPS...\n",
       "2            0  Dear The @CAPS1 newspaper, @CAPS2 in front of ...\n",
       "3            0  Dear @CAPS1 Society: Computers are perhaps one...\n",
       "4            0  Dear @ORGANIZATION1, The creation of computers...\n",
       "..         ...                                                ...\n",
       "795          7   We couldn't control our selves, our eyes wate...\n",
       "796          7    It all started at the play ground @CAPS9 me ...\n",
       "797          7   For my family laughter is important to us bec...\n",
       "798          7   Laughter, one of the greatest gifts in life. ...\n",
       "799          7   Why is it that people can look back at someth...\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hewlett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the responses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     800.000000\n",
       "mean      465.585000\n",
       "std       246.627283\n",
       "min       205.000000\n",
       "25%       254.000000\n",
       "50%       351.500000\n",
       "75%       718.000000\n",
       "max      1064.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of words in the responses:\")\n",
    "df_hewlett[\"text\"].apply(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Expand the bert column into 768 columns\\ndf_hewlett = pd.concat(\\n    [df_hewlett, pd.DataFrame(np.zeros((len(df_hewlett), 768)))], axis=1\\n)\\ndf_hewlett.columns = index\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Expand the bert column into 768 columns\n",
    "df_hewlett = pd.concat(\n",
    "    [df_hewlett, pd.DataFrame(np.zeros((len(df_hewlett), 768)))], axis=1\n",
    ")\n",
    "df_hewlett.columns = index\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Laughter in life is a good thing to have I believe. Once @CAPS3 I was @NUM1 year's old I had a and @CAPS1. We always loved to hang out and do things together like take walks, or go to the beach, or go to the parks. What was so funny was that that we also loved to eat together too, maybe not out his dog bowl, but off of plates or on a picnic table. He was a cute dog. He had four little puppies named @CAPS5-@CAPS6, popcorn,big tail, and mountain. I named them all weird animal names because that's either what they smelled like or that's what they looked or loved doing.  Why we named my dog @CAPS1 was because he always smelt like @CAPS1. I always took him on walks to make him a healthy dog. It made me very angry @CAPS3 he had puppies and a mate. I don't know why maybe just because head I really loved my dog and i wanted him to be mine only. My favorite friend. I thought in my head hey! that's my dog and you leave him alone and do not touch him. Well @CAPS3 he had puppies i finally realized in my head @CAPS1 just wanted a life of his own too, a family, and be a big boy dog. He didn't hate me, he loved me and giving him a family is what I allowed and it made him happy. What was funny about the little puppies was that they smelt like odd food, like @CAPS1, @CAPS5 chops, or popcorn. My favorite puppy was @CAPS5 @CAPS6 because that's what he smelt like, not @CAPS1 but @CAPS5. POPCORN was a good dog too so was the other dogs but @CAPS5 @CAPS6 was a biter. It's funny because those little puppies love to bite and chew on stuff. The second you leave my puppies alone they will so eat everything. One time @CAPS3 we went on a trip to another state he had to leave the puppies alone with a babysitter, and @CAPS3 we came back they ate up a lot of the clothes and destroyed everything. I also had @CAPS11 too but they weren't good animals or pets to have they also ate everything up, and they stink. No not like @CAPS1 or popcorn but something else gross. The puppies loved to nibble on your toes and your hair. They had small teeth but oh they hurt. Stinky breath those dogs had I don't know why but there stinky. One of my favorite story about @CAPS1 was that he never liked to swim. It was odd to me because you would have thought cats hate water more than dogs. Well @CAPS1 did not know how to swim so I had to teach him myself as a good owner and all. Well @CAPS3 ever he doggy-paddled, he stuck his head underwater and swam forward. I don't know why, but I always thought can he breath like that? or is it just a doggy thing. Well eventually I got him over that, I don't think it was good for him to swim underwater. Like cats he used to never like water, it was just a phobia my dog had I guess. But I tried my best to get him over it. @CAPS3 I moved around states I had to leave him it was the saddest thing in my life ever. But we all move on right. Laughter I think is so good to have in your life because it can help you become more anti-depressed and not have to focus on the bad things in life. Every now and then @CAPS3 I am sad i just go and think of @CAPS1. I had other animals like @CAPS10, @CAPS11, @CAPS12, and cats. Personally I love cats more than dogs but @CAPS1 will always be the first. My cats weren't really that social to me, there lazy.What was so funny about my cats was that I named one of them @CAPS14. Why I named that cat @CAPS14 was because he was all black but with white feet. It was funny because @CAPS3 ever he got mad he did a lot of turning and jumping around. He was a wild kitty. I named one of my cats @CAPS15 because he was so fast at everything. What was funny about him was @CAPS3 ever you play around with him he charged off like he ate a bowl of cat nip. Having animals in my life to be with gave me a story of laughter in my life, and happiness. Laughter I think is a good important part of relationships too. If you do not laugh in your relationship then I believe that the couple are not so happy. Laughter can be good many time's, but also can be a insult too. If it means becoming a insult to some people or even laughing at people is rude.  Having laughter in your life is something you should always keep because it can help you become happy in many situations and problems you encounter in life. To be happy you should have laughter.\n",
      "\n",
      " It all began when my best guy friend @CAPS9 the time asked @CAPS7 to go to the lake that @DATE1 with a bunch of people , I mean how could I turn that down getting tan with friends, swimming I mean it sounded fun in all so I decided to say yes @CAPS5 really fast too. I was sitting on the couch when all the sudden my phone started ringing I hurried to pick it up.. it was @PERSON2 \" @PERSON1... @PERSON2 said \" \"yeah, whats up \" \"your coming right tomorrow right.. @PERSON2 continued \"\"yeah, of course what time though.\"  \"@CAPS2 going to be @CAPS9 your house @CAPS9 @NUM1 be ready @CAPS2 being @NUM2 exlaimed\" \" alright alright ,ill see you tomorrow.. @CAPS3 I hung up the phone.\"  The next day I layed in bed wide awake @CAPS9 @TIME1 @CAPS5 was unable to even think about sleeping any more I was so excited I had that feeling where I just knew it was going to be a good day @CAPS5 knew it was going to be so much fun. Nine o clock came faster @CAPS3 ever, I jumped out of bed @CAPS5 went straight to the bathroom to get ready, @CAPS5 begin packing my beach bag. @CAPS3 finally @NUM1 rolled around, @CAPS5 my phone started going off agin @CAPS5 it was @PERSON2 \" you ready!? were outside your house .. @PERSON2 said\" \"yep, @CAPS2 coming right now..bye \" I got in the car with it jamed full of guys @CAPS5 we took off.   @CAPS9 about two o clock we got to the lake @CAPS5 all began getting out of the car @CAPS5 started stretching @CAPS3 @CAPS3 all the boys started stripping off their clothes until just there swimming shorts @CAPS5 @CAPS3 all started running right towards the water @CAPS5 all hopped in. So right away I began taking my clothes off so now all I had on was my swimsuit @CAPS3 I stared walking down too. Finally @PERSON2 comes up @CAPS5 starts telling @CAPS7 to hurry \" @CAPS1'mon @PERSON1 hurry it up run I want you to get in...\" \" I know @CAPS2 coming.. @CAPS5 @CAPS2 going to get in dont worry @PERSON2.. \" @CAPS3 out of no where @PERSON2 grabes my hand @CAPS5 begins making @CAPS7 run down towards the water. When all the sudden we hit this like muddy patch of walk way area that looked like bird poop @CAPS5 mud mixed together. As soon as my feet hit the mud , while I was running I slipped @CAPS5 fell right in front of the guy I liked @CAPS9 the time \"@PERSON2\". I had never been more embarrassed in life, but I played it out cool, @CAPS5 since everyone else was laughing @CAPS9 @CAPS7 I decided to start laughing too. @CAPS3 I notcied that once everyone had stopped laughing no one really cared enough to make it that big of deal. So I hopped back up with the help of @PERSON2's hand @CAPS5 @CAPS3 notcied that since I had just slipped in mud/poop that it was all over the butt. @CAPS9 that point I dont think I could have been more embarrassed about what had just happened..I had slipped in mud, @CAPS5 it was all over @CAPS7. After that had happen I didnt really care anymore about being embarrassed, so I walked on down to the water @CAPS5 got in right away @CAPS5 swam around a little bit so that the mud would wash away, @CAPS5 thank @CAPS4 it did. About twenty mintues later were all sitting in the sand @CAPS5 just telling stories @CAPS5 hanging out, when @PERSON2 looks over in the water @CAPS5 notices that there is a huge \"water slug\" in the water right by him, so him being a guy, he decides to go over @CAPS5 grab the slug @CAPS5 hold on to it, @CAPS5 of course.. I freak out @CAPS5 get up @CAPS5 kind of take a few steps back. @PERSON2 starts asking \" @CAPS5 who do I want to throgh this @CAPS9\" everyone @CAPS9 the point is saying \" not @CAPS7.. NOT @CAPS7\". I just stood there quit, when he looks over @CAPS9 @CAPS7 I stare back @CAPS9 him with a scared look on my face @CAPS5 say \" @CAPS5 you wouldnt through that @CAPS9 @CAPS7 becauase @CAPS2 a good friend of yours right?.. now would you.\" @CAPS9 this point since right before this we were all sitting in the sand talking,I had put on a tank top @CAPS5 shorts over my swin suit, when all the sudden I hear \" @PERSON1 watch out\" I had turned around for a second... @CAPS9 the most, to look @CAPS9 something, @CAPS3 I feel this slimy long wet thing side down my shirt. I look down my shirt @CAPS5 see this slug in side of my shirt. I start freaking out @CAPS5 screaming as loud as I could @CAPS5 jumping around. @CAPS5 just when I thought it was out I look down @CAPS5 its still there finally it comes popping out of my shirt, @CAPS5 I just sat there calming down from what juast happend. Oh what a day!!\n",
      "\n",
      " Laughter is something that you should make an important part of your everyday life. In most cases laughter can brake the ice and can make people more comfortable with each other. When with friends and family most likely some of your best memory are made when there is something going on that made you laugh. Laughing not only puts yourself in a good mood but also every one around you. When you can make everyone laugh and put people in a good mood, in most cases you will be viewed as a fun, self confident person.  In the scorching @DATE1 my cousin @PERSON4, myself and two of his friends I had not met yet planned a camping trip. Our idea was that we are going down to the river about two miles away from @CAPS1 house and camp out for @NUM1 nights. We planed to make time the second day for us all to hike up the beautiful river to the falls for the day. When we first arrived i met is friends @PERSON2 and @PERSON3. We where all busy the first few hours setting up camp. Once camp was set up we made a fire and sat around it. The evening was awkward and silent for a short time because none of us other than @PERSON4 knew each other. Things started to get better when @PERSON4 started telling everyone about the prank war me and him had been having over the past few months. @CAPS2 started  \" this whole thing started when @PERSON1 put plastic wrap outside of my door so I ran in to it when i woke up in the morning.\" I interrupted. \" no actually this started because @PERSON4 called me short and made fun of me, I cant help that im not tall.\"  @CAPS2 continued his story about all the pranks we had pulled on each other like how i put butter all over his kitchen floor, then called his house phone so when @CAPS2 ran in there to answer it @CAPS2 slipped. @CAPS2 told of how @CAPS2 put his snake in my bed and scared me and how @CAPS2 filled my bathtub with green jello. After some good laughs we all warmed up and started talking and telling our own stories. Later that day we all went down to the river. @PERSON4 saw a small lime green frog and picked it up. @CAPS2 held it up to my face and said  \" kiss it @PERSON1 maybe it will turn in to a prince! \", I said \" no way dude im not going to kiss a frog\" @CAPS2 replied with \" and this is why you will never find true love @PERSON1 i mean you got to take a chance now and then you know.\"I told him that I had a prince and @CAPS2 was much more handsome then the frog could ever become.  After a good time at the river we went back up to camp and ate dinner and talked some more around the fire. That night @PERSON4 broke the zipper on his tent so lucky me I had to share my tent with him. After everyone went to bed we went out of the tent and where getting something to eat when @PERSON4 said \"whoa did you see that!\" as @CAPS2 quickly looked up at the sky. Naturally I looked up and said \"what is it.\" @CAPS2 just laughed at me because there was nothing there @CAPS2 just wanted me to look.  The next morning after breakfast me, @PERSON2, and @PERSON3 all went down to the river again and jumped in. @PERSON4 soon joined us. I noticed that there was a bunch of small fish in the water and i pointed them out to @PERSON4. The first thing @CAPS2 said was \"if you can catch one of those with your hands ill eat it hole\" I said \"your on\" so I struggled in the water trying to catch a little fish for around @NUM2 minutes. This whole time the guys are having fun laughing at me struggle and get all wet trying to catch the little fish. Finlay I got one! I walked over to @PERSON4 with the fish in my hand and smiled. @CAPS2 grabbed it out of my hand and put it in his mouth and swallow it, @CAPS2 quickly grabbed my hand and put it on his throat. I could feel the fish wiggling down his neck. I thought it was gross but then very funny because i didn't really expect him to do it.  The rest of the @ORGANIZATION1 consisted of some good laughs and some good memory's made. @PERSON2 somehow got coal from the fire on his forehead and we all giggled knowing @CAPS2 had no idea it was there for about @NUM1 hours. I caught @PERSON3 singing and dancing to himself by the river one evening, it was pretty hilarious but I kept that one to myself. Over all the camping trip was one of the best. I had a great time and made some new friends. It is truly an experience I will not soon forget.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = df_hewlett[df_hewlett[\"prompt_id\"] == 7].head(3)[\"text\"].to_list()\n",
    "\n",
    "for y in x:\n",
    "    print(y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM response generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini (1.0 and 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "\n",
    "with open(\"API_KEY_GOOGLE.txt\", \"r\") as f:\n",
    "    API_KEY_GOOGLE = f.read()\n",
    "\n",
    "genai.configure(api_key=API_KEY_GOOGLE)\n",
    "\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "gemini_10_pro = genai.GenerativeModel(\n",
    "    \"models/gemini-1.0-pro\", safety_settings=safety_settings\n",
    ")\n",
    "\n",
    "gemini_15_pro = genai.GenerativeModel(\n",
    "    \"models/gemini-1.5-pro-latest\", safety_settings=safety_settings\n",
    ")\n",
    "\n",
    "\n",
    "def generate_gemini(model, model_name, prompt):\n",
    "    while True:\n",
    "        start = time.time()\n",
    "        response = model.generate_content(prompt)\n",
    "        # Gemini sometimes returns an empty response due to \"SAFETY\", so try again\n",
    "        if not response.parts:\n",
    "            print(response.candidates)\n",
    "            continue\n",
    "        # Gemini has a rate limit of 15 requests per minute for 1.0 and 2 requests per minute for 1.5\n",
    "        wait_time = 30 if \"1.5\" in model_name else 4\n",
    "        time.sleep(max(0, wait_time + 1 - (time.time() - start)))\n",
    "        return \" \".join([part.text for part in response.parts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT (3.5 and 4.0 and 3.5 over a range of temperature values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "with open(\"API_KEY_OPENAI.txt\", \"r\") as f:\n",
    "    API_KEY_OPENAI = f.read()\n",
    "\n",
    "\n",
    "model_name_35 = \"gpt-3.5-turbo-0125\"\n",
    "model_name_4 = \"gpt-4-turbo-2024-04-09\"\n",
    "\n",
    "\n",
    "def generate_gpt(model_name, prompt, temp=None):\n",
    "    client = OpenAI(api_key=API_KEY_OPENAI)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    response = None\n",
    "    if temp:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            temperature=temp,\n",
    "        )\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude (Sonnet and Opus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "with open(\"API_KEY_ANTHROPIC.txt\", \"r\") as f:\n",
    "    API_KEY_ANTHROPIC = f.read()\n",
    "\n",
    "\n",
    "model_name_sonnet = \"claude-3-sonnet-20240229\"\n",
    "model_name_opus = \"claude-3-opus-20240229\"\n",
    "\n",
    "\n",
    "def generate_claude(model_name, prompt):\n",
    "    client = anthropic.Anthropic(api_key=API_KEY_ANTHROPIC)\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=model_name,\n",
    "        max_tokens=4096,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(model_name, dataset_name):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:27<00:00, 10.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Here is a draft letter to the editor stating my opinion on the effects of computers on people:\\n\\nDear Editor,\\n\\nI am writing in response to the ongoing debate about the impacts of computers on society. While I recognize there are valid concerns about overuse and unhealthy habits, I ultimately believe that computers and technology have an overall positive effect on people\\'s lives.  \\n\\nOn the positive side, computers open up vast realms of knowledge, learning, and connectivity that were impossible in previous eras. With just an internet connection, anyone can instantly access libraries of information on any topic they wish to explore, satisfying our innate human curiosity. Students have universes of educational resources at their fingertips. Computers also allow global communication - the ability to build communities, collaborate with peers around the world, and develop cross-cultural understanding. These are incredibly enriching benefits.\\n\\nFurthermore, coding, digital creation, and the \"maker\" culture that computers enable can foster valuable skills like logic, problem-solving, creativity and entrepreneurship from a young age. Many would argue these skills are more vital than ever in our rapidly changing world. Assistive technologies are also empowering people with disabilities and opening up new frontiers of access and independence.\\n\\nAt the same time, I agree that we must be mindful of potential downsides like internet overuse, isolation, misinformation, privacy concerns, and disruption of face-to-face social skills. However, the answer is not technophobia, but balance and education. We should teach digital literacy, healthy tech habits, and self-regulation from an early age, just as we teach nutrition, manners and other life skills. Used wisely, computers remain a net positive for society.\\n\\nWhile no technology is perfect, the computer revolution has been an incredible engine of human progress, creativity and interconnection. By celebrating its benefits while fortifying ourselves against potential drawbacks, we can embrace the future it enables.\\n\\nSincerely,\\n[Your name]',\n",
       " \"Here is a draft persuasive essay against censorship in libraries:\\n\\nCensorship in Libraries Goes Against Democratic Values\\n\\nPublic libraries are one of our most important democratic institutions. They provide free and open access to information, ideas, and works of art and literature for all citizens, regardless of their age, background, or beliefs. Censoring library materials is a violation of our core democratic values of freedom of speech and freedom of thought. \\n\\nThose in favor of censoring books, movies, music or other materials that they find offensive are actually undermining democracy itself. Democracy is based on the principle that even unpopular or controversial ideas should be allowed to be expressed and encountered in the marketplace of ideas. Censorship shuts down this free exchange of ideas and imposes the restrictive values of a small group on everyone else.\\n\\nWe may not like or agree with every idea or artistic work available in a public library. But that's the price we pay to live in a free society. Once we start banning books, movies, albums or artworks that are offensive to some people, we start downa very slippery slope. Different groups will have different definitions of what is offensive or objectionable. Religious fundamentalists may want to ban books that contradict their beliefs. Political groups may want to ban works that insult their ideologies. Before long, our libraries will be empty of any meaningful content.\\n\\nAs the author Katherine Paterson said, if you give yourself the right to remove one book you abhor from the library, you are giving that right to every other group as well. And soon there will be no books left that don't offend someone's sensibilities. That is the antithesis of what a public library hopes to achieve - expanding our access to a wide range of information and ideas.\\n\\nSome may argue that protecting children from inappropriate content is a valid reason for censorship in libraries. But libraries already restrict access to age-inappropriate content for children. There are clear policies and practices in place to prevent young children from accessing pornography, extremely violent content, or other obscene materials. Many libraries have special children's sections with properly segregated and age-appropriate content. But preventing children from accessing age-inappropriate content does not require wholesale censorship of library materials.\\n\\nIn a truly free society, we must be willing to encounter ideas or artistic works that we may find disagreeable or offensive. Public libraries should continue to make a wide range of content available, while enforcing reasonable policies to prevent access to obscene materials by children. Anything less than that open access to information and ideas is a step toward undermining our core democratic values.\",\n",
       " 'The harsh and unforgiving setting of the desert terrain significantly impacts the cyclist\\'s journey, leading to his physical distress and near-fatal situation. The essay vividly portrays how the features of the environment, such as the scorching heat, lack of water sources, and rugged terrain, put the cyclist\\'s well-being at risk and challenge his endurance.\\n\\nOne of the key factors affecting the cyclist is the intense heat of the California desert in June. The essay mentions that the cyclist is \"traveling through the high deserts of California in June,\" implying the extreme temperatures he faces. The heat is exacerbated by the lack of water sources, as the \"brackish water\" from the rusted pump feels \"somewhere in the neighborhood of two hundred degrees,\" making it undrinkable. The heat and dehydration take a toll on the cyclist, causing him to experience \"dried sweat\" circling his shirt and a \"deteriorating brain.\"\\n\\nThe rugged and unpredictable terrain also presents a significant challenge. The essay describes how the initially flat road is replaced by \"short, rolling hills,\" and a highway sign warns of a \"ROUGH ROAD AHEAD.\" These obstacles demand physical exertion and drain the cyclist\\'s energy reserves, further exacerbating his dehydration. Even the presence of a \"ridiculously large snake\" blocking the road adds to the hazardous conditions he faces.\\n\\nThe setting\\'s desolation and lack of human habitation also contribute to the cyclist\\'s predicament. The essay mentions the \"ghost town\" and the \"abandoned\" Welch\\'s Grape Juice factory, highlighting the absence of potential sources of aid or water. This isolation amplifies the cyclist\\'s sense of vulnerability and hopelessness, as he laments the prospect of \"dying\" with no one to rescue him.\\n\\nThroughout the essay, the author skillfully uses vivid descriptions of the setting to convey the harsh and unforgiving conditions the cyclist encounters. The examples of the scorching heat, lack of water, rugged terrain, and desolation effectively illustrate how the features of the setting pose significant physical and psychological challenges, pushing the cyclist to the brink of exhaustion and despair.',\n",
       " 'The author concludes the story with this paragraph to symbolize Saeng\\'s renewed determination and hope for the future, despite the challenges she has faced as a Vietnamese immigrant adapting to life in the United States.\\n\\nThroughout the story, Saeng experiences a profound sense of nostalgia and loss for her homeland and cultural roots when she encounters familiar plants like the hibiscus and jasmine at the florist shop. These plants evoke vivid memories of her childhood in Vietnam, causing her to break down and weep. However, her mother\\'s act of planting the \"winter hibiscus\" in their garden represents an effort to preserve a piece of their cultural heritage and adapt it to their new environment.\\n\\nThe last paragraph serves as a powerful symbol of Saeng\\'s resilience and her ability to find strength in the natural cycle of seasons and the continuity of life. The return of the geese and the budding of the hibiscus in the spring symbolize rebirth and renewal, giving Saeng the resolve to try again and overcome her setback of failing the driver\\'s test.\\n\\nBy linking Saeng\\'s determination to retake the test with the arrival of spring and the blooming of the hibiscus, the author suggests that Saeng is embracing her new life in America while maintaining a connection to her Vietnamese roots. The hibiscus, which her mother calls a \"winter hibiscus,\" represents Saeng\\'s ability to adapt and thrive in her new environment, just as the plant has adapted to survive the cold winters.\\n\\nOverall, the concluding paragraph is a poignant and hopeful note, reflecting Saeng\\'s journey of cultural adjustment and her resilience in the face of challenges, symbolized by the natural cycles of renewal and the enduring presence of her cultural heritage embodied in the hibiscus plant.',\n",
       " 'The author creates a warm, nostalgic, and appreciative mood throughout the memoir as he fondly reminisces about his childhood home and the lessons he learned from his parents\\' resilience and generosity.\\n\\nThe warmth and affection are evident in the vivid descriptions of his family\\'s humble yet lively home, where \"the innocence of childhood, the congregation of family and friends, and endless celebrations\" formed the backdrop. He recalls the aromas of Cuban cuisine wafting from the kitchen, mingling with the passionate music that filled the air, creating a cozy and inviting atmosphere.\\n\\nThe nostalgia is palpable as he recounts the close-knit community of immigrants who supported each other, extending a hand to those in need, regardless of their backgrounds. He fondly mentions his babysitter and first friend, Alegria, as well as his surrogate grandparents, aunts, and cousins who were a constant presence at their table, emphasizing the strong sense of family that transcended blood ties.\\n\\nThroughout the memoir, the author expresses deep gratitude and admiration for his parents\\' courage, sacrifices, and unwavering spirit. He acknowledges the hardships they endured as immigrants, leaving behind their careers and loved ones in Cuba to provide a better life for their children. Despite the challenges, his parents maintained a spirit of generosity, welcoming other refugees into their home and celebrating their arrival in the United States.\\n\\nThe author\\'s appreciation for the lessons instilled by his parents is evident in his statement: \"It was here where I learned the real definition of \\'family.\\' And for this, I will never forget that house or its gracious neighborhood or the many things I learned there about how to love.\" This sentiment underscores the lasting impact of his childhood experiences and the profound gratitude he feels towards his parents and their humble home, which he fondly refers to as \"the very heart\" of their traditional Cuban upbringing.',\n",
       " 'The builders of the Empire State Building faced several significant obstacles in their attempt to allow dirigibles to dock at the top of the building:\\n\\n1. Safety concerns: The excerpt mentions that the use of highly flammable hydrogen gas by most dirigibles outside the United States posed a severe safety risk, especially in a densely populated area like downtown New York. This concern was heightened after the catastrophic fire that destroyed the Hindenburg dirigible in 1937.\\n\\n2. Wind conditions: The excerpt states that the winds at the top of the building were constantly shifting due to violent air currents, which would cause the back of a tethered dirigible to swivel around the mooring mast uncontrollably. This made it practically impossible to safely moor dirigibles at that height.\\n\\n3. Legal restrictions: There were existing laws prohibiting airships from flying too low over urban areas, which would make it illegal for a dirigible to approach and tie up to the Empire State Building.\\n\\n4. Structural modifications: Extensive and costly modifications, worth over $60,000 at the time, had to be made to the building\\'s steel frame to accommodate the stress and wind pressure exerted by a moored 1,000-foot dirigible tethered at the top.\\n\\nThe excerpt provides specific evidence to support these obstacles, such as the failed attempt by the U.S. Navy dirigible Los Angeles to approach the mooring mast due to forceful winds, and the architects\\' acknowledgment in 1931 that \"the as yet unsolved problems of mooring air ships to a fixed mast at such a height made it desirable to postpone to a later date the final installation of the landing gear.\"',\n",
       " \"Here is a story about a time when I had to be patient:\\n\\nIt was the week before my big presentation at work. I had been preparing for months, putting together a detailed slide deck and rehearsing over and over. The presentation was scheduled for Friday morning in the main conference room in front of all the executives. \\n\\nOn Wednesday afternoon, a major issue came up with one of our systems that took all hands on deck to resolve. I ended up working around the clock troubleshooting the issue until late Thursday night. I didn't get any sleep, my presentation materials were scattered, and I felt completely frazzled and unprepared.\\n\\nWhen Friday morning came, I was exhausted, but I knew I had to pull it together. I took a few deep breaths, organized my slides, and went over my notes one more time on the way to the conference room. The meeting started, and I could feel my heart pounding as I was introduced.  \\n\\nBut once I started going through the presentation, I found my groove. I was patient, took my time explaining each slide, and didn't let myself get flustered when interrupted with questions. An hour later, I wrapped up to applause from the executives.\\n\\nIt took a tremendous amount of patience to push through that stressful situation with no sleep and clear that major hurdle. But staying calm and being patient with myself and the process allowed me to deliver what ended up being one of my strongest presentations. It was a good reminder that patience can often be the key to success.\",\n",
       " 'Here\\'s a true story about how laughter played a role in strengthening a friendship:\\n\\nDuring my junior year of college, my best friend Sarah and I decided to take a weekend road trip to a nearby city. We packed up her old Honda Civic and hit the road, looking forward to exploring a new place and having some adventures together.\\n\\nThe first hint that this trip wouldn\\'t go as planned came when Sarah\\'s car started making an ominous rattling noise about an hour into the drive. We pulled over, but neither of us could figure out what was wrong. With a shrug, we decided to keep going and hope for the best.\\n\\nWe made it to our destination without any further car issues, checked into our hotel, and began exploring the city. That\\'s when the real fun began. Between getting lost and wandering into some questionable neighborhoods, failing miserably at operating a stick shift car we had rented, and a couple of truly awful restaurant choices, we encountered one comedic mishap after another.\\n\\nAt first, we were a bit stressed, but eventually, the absurdity of it all became hilarious to us. We started laughing at every new blunder, crying with mirth as we recounted each silly moment to one another. Our laughter grew more intense and more welcome with each passing hour.\\n\\nOn the drive back to campus, Sarah\\'s car decided to add to the humor by overheating and leaving us stranded. As we sat on the side of the highway, waiting for a tow truck and howling with laughter, I realized something. Despite all the things that had gone wrong, I was actually having one of the best times of my life – all because Sarah and I were choosing to embrace the humorous side of our misadventures.\\n\\nFrom then on, no matter what curve balls life threw our way, we faced them together with laughter. Even decades later, all I have to do is remind Sarah about \"the weekend of calamities,\" and we both dissolve into giggles. Laughter became the glue that held our friendship together through good times and bad. It reminded us not to take life too seriously and to find the humor in any situation. Most importantly, it created an unbreakable bond between us that still holds strong today.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "r = []\n",
    "df_hewlett_prompts = pd.read_csv(\"hewlett_prompts.csv\")\n",
    "for prompt in tqdm(df_hewlett_prompts[\"prompt\"].to_list()):\n",
    "    r.append(generate_claude(model_name_sonnet, prompt))\n",
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
